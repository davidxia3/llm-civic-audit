{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b1ce511b",
   "metadata": {},
   "source": [
    "# Module 2: Transcript Processing\n",
    "- Step 1: Transcribe meeting audio\n",
    "- Step 2: Repunctuate raw transcript and split into sentences\n",
    "- Step 3: MANUAL sentence classification\n",
    "- Step 4: Segment transcription based on manual sentence classification\n",
    "- Step 5: MANUALLY match transcript segments to agenda segments of same meeting's agenda\n",
    "- Step 6: Combine agenda, legislation, and transcript segments to form combined segments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8766defb",
   "metadata": {},
   "source": [
    "Specify the week of meetings to process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7ad88ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### EDIT THIS\n",
    "MONDAY_DATE = \"YYYYMMDD\"\n",
    "FRIDAY_DATE = \"YYYYMMDD\"\n",
    "#### EDIT THIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5952f8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "WEEK = (MONDAY_DATE, FRIDAY_DATE)\n",
    "START_DATE = datetime.strptime(WEEK[0], \"%Y%m%d\")\n",
    "END_DATE = datetime.strptime(WEEK[1], \"%Y%m%d\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7f582c7",
   "metadata": {},
   "source": [
    "## Step 1: Transcribe meeting audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e8e35fd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import whisper\n",
    "import regex as regex\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a928125",
   "metadata": {},
   "source": [
    "The folder `___input/audio/` should contain a `.wav` audio file for each city council meeting. Each `.wav` file should be named such that the first 8 characters are the meeting date in YYYYMMDD format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2851f8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_AUDIO_PATH = Path(\"../___input/audio/\")\n",
    "assert INPUT_AUDIO_PATH.exists()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "092aed9a",
   "metadata": {},
   "source": [
    "The agenda `.txt` files containing the transcript will be saved to `_interim/transcript/`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdcd4983",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRANSCRIPT_PATH = Path(\"../_interim/transcript/\")\n",
    "TRANSCRIPT_PATH.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e42e7504",
   "metadata": {},
   "source": [
    "Transcribe the audio with OpenAI Whisper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9b59ba4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use mps:0\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/transformers/pipelines/token_classification.py:186: UserWarning: `grouped_entities` is deprecated and will be removed in version v5.0.0, defaulted to `aggregation_strategy=\"AggregationStrategy.NONE\"` instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "asr_model = whisper.load_model(\"large\")\n",
    "punct_model = PunctuationModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ea2a27f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/whisper/transcribe.py:132: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
     ]
    }
   ],
   "source": [
    "for audio_file in INPUT_AUDIO_PATH.glob(\"*.wav\"):\n",
    "        \n",
    "    # check if meeting took place in specified week\n",
    "    date_str = audio_file.stem[:8]\n",
    "    try:\n",
    "        file_date = datetime.strptime(date_str, \"%Y%m%d\")\n",
    "    except ValueError:\n",
    "        # skip, meeting does not valid date\n",
    "        continue\n",
    "    if file_date < START_DATE or file_date > END_DATE:\n",
    "        # skip, meeting did not take place in specified week\n",
    "        continue\n",
    "\n",
    "    # transcribe audio\n",
    "    stem = audio_file.stem\n",
    "    transcript_txt_path = TRANSCRIPT_PATH / f\"{stem}.txt\"\n",
    "    result = asr_model.transcribe(str(audio_file), language=\"en\")\n",
    "\n",
    "    with open(transcript_txt_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(result[\"text\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f562fa50",
   "metadata": {},
   "source": [
    "## Step 2: Repunctuate raw transcript and split into sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21d5b01a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import re\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import regex as regex\n",
    "from deepmultilingualpunctuation import PunctuationModel\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fabac6a5",
   "metadata": {},
   "source": [
    "The folder `_interim/transcript/` should now contain a `.txt` file containing the transcribed audio of each meeting. The sentences of the transcript are saved to the folder `_interim/transcript_sentences/` and the cleaned transcript text are saved back to the original destination."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b36ebbd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert TRANSCRIPT_PATH.exists()\n",
    "TRANSCRIPT_SENTENCES_PATH = Path(\"../_interim/transcript_sentences/\")\n",
    "TRANSCRIPT_SENTENCES_PATH.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb64d83e",
   "metadata": {},
   "source": [
    "Remove punctuation, clean raw text, repunctuate, and then split into sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b00f1010",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/nn/modules/module.py:1541: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `XLMRobertaSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "for raw_transcript_file in TRANSCRIPT_PATH.glob(\"*.txt\"):\n",
    "\n",
    "    # check if meeting took place in specified week\n",
    "    date_str = raw_transcript_file.stem[:8]\n",
    "    try:\n",
    "        file_date = datetime.strptime(date_str, \"%Y%m%d\")\n",
    "    except ValueError:\n",
    "        # skip, meeting does not valid date\n",
    "        continue\n",
    "    if file_date < START_DATE or file_date > END_DATE:\n",
    "        # skip, meeting did not take place in specified week\n",
    "        continue\n",
    "\n",
    "\n",
    "    # clean and remove punctuation\n",
    "    with open(raw_transcript_file, \"r\", encoding=\"utf-8\") as f:\n",
    "        raw = f.read()\n",
    "\n",
    "    raw = re.sub(r\"\\[.*?\\]\", \"\", raw)\n",
    "    # remove punctuation-based segment endings\n",
    "    raw = raw.replace(\". \", \" \").replace(\"? \", \" \").replace(\"! \", \" \").replace(\", \", \" \")\n",
    "    # remove non-Latin characters\n",
    "    raw = regex.sub(r'[^\\p{Latin}\\d\\p{P}\\s]', '', raw)\n",
    "    # normalize whitespace and remove filler words\n",
    "    raw = re.sub(r'\\b(?:uh|um)+\\b[,.]?\\s*', '', raw, flags=re.IGNORECASE)\n",
    "    raw = re.sub(r'\\s+', ' ', raw)\n",
    "    clean =  raw.strip()\n",
    "\n",
    "    # repunctuate text\n",
    "    punctuated_text = punct_model.restore_punctuation(clean)\n",
    "\n",
    "    # split into sentences\n",
    "    sentences = re.findall(r'[^.!?]*[.!?]', punctuated_text)\n",
    "    sentences = [s.strip() for s in sentences if s.strip()]\n",
    "\n",
    "\n",
    "    # save sentences to .csv file\n",
    "    stem = raw_transcript_file.stem\n",
    "    csv_output_path = TRANSCRIPT_SENTENCES_PATH / f\"{stem}.csv\"\n",
    "    with open(csv_output_path, \"w\", newline='', encoding=\"utf-8\") as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow([\"sentence\", \"classification\"])\n",
    "        for sentence in sentences:\n",
    "            writer.writerow([sentence, \"x\"])\n",
    "\n",
    "    # convert sentences to cleaned transcript and save cleaned transcript\n",
    "    clean_transcript_file_path = TRANSCRIPT_PATH / f\"{stem}.txt\"\n",
    "    df = pd.read_csv(csv_output_path)\n",
    "    full_text = \" \".join(df[\"sentence\"].dropna().astype(str))\n",
    "    with open(clean_transcript_file_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(full_text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af393ab5",
   "metadata": {},
   "source": [
    "## Step 3: MANUAL transcript segmentation via sentence classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4abae943",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7da1e1a",
   "metadata": {},
   "source": [
    "Now, the transcript sentences should be saved to the folder `_interim/transcript_sentences/`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "171706dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert TRANSCRIPT_SENTENCES_PATH.exists()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4b4ba922",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label each sentence as:\n",
      "  b - beginning of new topic\n",
      "  p - beginning of new public comment topic\n",
      "  i - inside a topic\n",
      "Type 'back' to go to the previous sentence.\n",
      "Type 'quit' to stop early and save your progress.\n",
      "\n",
      "\n",
      "1/6: The stale smell of old beer lingers.\n",
      "current label: x\n",
      "\n",
      "2/6: It takes heat to bring out the odor.\n",
      "current label: x\n",
      "\n",
      "3/6: A cold dip restores health and zest.\n",
      "current label: x\n",
      "\n",
      "4/6: A salt pickle tastes fine with ham.\n",
      "current label: x\n",
      "\n",
      "5/6: Tacos al pastor are my favorite.\n",
      "current label: x\n",
      "\n",
      "6/6: A zestful food is the hot cross bun.\n",
      "current label: x\n"
     ]
    }
   ],
   "source": [
    "for transcript_sentences_file in TRANSCRIPT_SENTENCES_PATH.glob(\"*.csv\"):\n",
    "    \n",
    "    # check if meeting took place in specified week\n",
    "    date_str = transcript_sentences_file.stem[:8]\n",
    "    try:\n",
    "        file_date = datetime.strptime(date_str, \"%Y%m%d\")\n",
    "    except ValueError:\n",
    "        # skip, meeting does not valid date\n",
    "        continue\n",
    "    if file_date < START_DATE or file_date > END_DATE:\n",
    "        # skip, meeting did not take place in specified week\n",
    "        continue\n",
    "\n",
    "    df = pd.read_csv(transcript_sentences_file)\n",
    "\n",
    "\n",
    "    # manual classification instructions\n",
    "    print(\"Label each sentence as:\")\n",
    "    print(\"  b - beginning of new topic\")\n",
    "    print(\"  p - beginning of new public comment topic\")\n",
    "    print(\"  i - inside a topic\")\n",
    "    print(\"Type 'back' to go to the previous sentence.\")\n",
    "    print(\"Type 'quit' to stop early and save your progress.\\n\")\n",
    "\n",
    "    # manual classification loop\n",
    "    idx = 0\n",
    "    while idx < len(df):\n",
    "        sentence = df.loc[idx, \"sentence\"]\n",
    "        current_label = df.loc[idx, \"classification\"]\n",
    "\n",
    "        print(f\"\\n{idx + 1}/{len(df)}: {sentence}\")\n",
    "        if current_label:\n",
    "            print(f\"current label: {current_label}\")\n",
    "\n",
    "        user_input = input(\"Label (b/p/i, or 'back', 'quit'): \").strip().lower()\n",
    "\n",
    "        if user_input in {\"b\", \"p\", \"i\"}:\n",
    "            df.at[idx, \"classification\"] = user_input\n",
    "            idx += 1\n",
    "        elif user_input == \"back\":\n",
    "            if idx > 0:\n",
    "                idx -= 1\n",
    "            else:\n",
    "                print(\"!!!! ALREADY AT BEGINNING\")\n",
    "        elif user_input == \"quit\":\n",
    "            break\n",
    "        else:\n",
    "            print(\"!!!! INVALID, PLEASE ENTER 'b', 'p', 'i', 'back', or 'quit'\")\n",
    "\n",
    "    # save classifications\n",
    "    df.to_csv(transcript_sentences_file, index=False)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33c42f92",
   "metadata": {},
   "source": [
    "## Step 4: Segment transcript using manual classification of sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0c9365f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import csv\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f38aaf25",
   "metadata": {},
   "source": [
    "The folder `_interim/transcript_sentences/` should have a `.csv` file for each meeting, containing a column for the sentences and another column for the manual classification. The segments will be saved to the folder `_interim/transcript_segments/`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd18adcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert TRANSCRIPT_SENTENCES_PATH.exists()\n",
    "TRANSCRIPT_SEGMENTS_PATH = Path(\"../_interim/transcript_segments/\")\n",
    "TRANSCRIPT_SEGMENTS_PATH.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd137a2f",
   "metadata": {},
   "source": [
    "Combine adjacent sentences in the transcript into segments. The `b` and `p` labels denote beginning of new segments. The `i` label denotes a continuation of a segment. Do not include segments that start with `p` sentences in the final segment file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98294843",
   "metadata": {},
   "outputs": [],
   "source": [
    "for transcript_sentences_file in TRANSCRIPT_SENTENCES_PATH.glob(\"*.csv\"):\n",
    "\n",
    "    # check if meeting took place in specified week\n",
    "    date_str = transcript_sentences_file.stem[:8]\n",
    "    try:\n",
    "        file_date = datetime.strptime(date_str, \"%Y%m%d\")\n",
    "    except ValueError:\n",
    "        # skip, meeting does not valid date\n",
    "        continue\n",
    "    if file_date < START_DATE or file_date > END_DATE:\n",
    "        # skip, meeting did not take place in specified week\n",
    "        continue\n",
    "\n",
    "\n",
    "    # combine adjacent sentences into segments based on each sentence's classification\n",
    "    df = pd.read_csv(transcript_sentences_file)\n",
    "    # remove irrelevant rows\n",
    "    df = df[df[\"classification\"] != \"f\"].reset_index(drop=True)\n",
    "    # skip any initial content before the first 'b' or 'p'\n",
    "    start_index = df[df[\"classification\"].isin([\"b\", \"p\"])].index.min()\n",
    "    df = df.iloc[start_index:].reset_index(drop=True)\n",
    "\n",
    "    # do not include public comment segments\n",
    "    segments = []\n",
    "    current_segment = \"\"\n",
    "    is_public_comment = False\n",
    "    in_segment = False\n",
    "    for _, row in df.iterrows():\n",
    "        label = row[\"classification\"]\n",
    "        sentence = row[\"sentence\"]\n",
    "\n",
    "        if label == \"i\":\n",
    "            current_segment += sentence + \" \"\n",
    "        else:\n",
    "            # iff we're finishing a segment, and it's not a public comment, store it\n",
    "            if in_segment and not is_public_comment:\n",
    "                segments.append(current_segment.strip())\n",
    "\n",
    "            current_segment = sentence + \" \"\n",
    "            in_segment = True\n",
    "            is_public_comment = (label == \"p\")\n",
    "\n",
    "    # handle final segment\n",
    "    if in_segment and not is_public_comment:\n",
    "        segments.append(current_segment.strip())\n",
    "\n",
    "    # save segments to .csv\n",
    "    segments_file_path = TRANSCRIPT_SEGMENTS_PATH / f\"{transcript_sentences_file.stem}.csv\"\n",
    "    with open(segments_file_path, mode=\"w\", newline='', encoding=\"utf-8\") as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow([\"segment\", \"matched_agenda_segment\"])\n",
    "        for segment in segments:\n",
    "            writer.writerow([segment, -1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95f67448",
   "metadata": {},
   "source": [
    "## Step 5: MANUALLY match transcript segment to corresponding agenda segment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1213c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20e26793",
   "metadata": {},
   "source": [
    "The folder `_interim/transcript_segments/` should have a `.csv` file for each meeting, containing a column for the segments of the transcript. The folder `_interim/agenda_segments/` should have a `.csv` for each meeting containing the agenda segments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "888be5c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert TRANSCRIPT_SEGMENTS_PATH.exists()\n",
    "AGENDA_SEGMENTS_PATH = Path(\"../_interim/agenda_segments/\")\n",
    "assert AGENDA_SEGMENTS_PATH.exists()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a630a7b1",
   "metadata": {},
   "source": [
    "Manually match each transcript segment to the closest aligned agenda segment from the same meeting's agenda."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ec75e159",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "transcript segment 0: Good morning and welcome to the regular meeting of City Council on Tuesday, April 1st 2025.\n",
      "transcript segment 1: Will the clerk please take the roll? Mr Sharlin Here, Mr Coghill Here, Ms Gross Here, Mr Mosley Here, Mrs Kale-Smith, Mrs Strasburger Here, Mrs Warwick Mr Wilson, Mr LaValle, President Here, Five members present.\n",
      "transcript segment 2: Thank you, Please rise for the Pledge of Allegiance. Remain standing for a moment of silence. I pledge allegiance to the flag of the United States of America and to the republic for which it stands: one nation under God. one nation under God, indivisible, with liberty and justice for all. Thank you very much.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "Interrupted by user",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[24]\u001b[39m\u001b[32m, line 21\u001b[39m\n\u001b[32m     18\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mtranscript segment \u001b[39m\u001b[38;5;132;01m{\u001b[39;00midx\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrow[\u001b[33m'\u001b[39m\u001b[33msegment\u001b[39m\u001b[33m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     20\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m21\u001b[39m     user_input = \u001b[38;5;28;43minput\u001b[39;49m\u001b[43m(\u001b[49m\u001b[33;43mf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43menter the index of the closest aligned agenda segment (0-\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43magenda_df\u001b[49m\u001b[43m)\u001b[49m\u001b[43m-\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m inclusive). enter -1 if no match: \u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m.strip()\n\u001b[32m     22\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     23\u001b[39m         user_input = \u001b[38;5;28mint\u001b[39m(user_input)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/Python/3.11/lib/python/site-packages/ipykernel/kernelbase.py:1396\u001b[39m, in \u001b[36mKernel.raw_input\u001b[39m\u001b[34m(self, prompt)\u001b[39m\n\u001b[32m   1394\u001b[39m     msg = \u001b[33m\"\u001b[39m\u001b[33mraw_input was called, but this frontend does not support input requests.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1395\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m StdinNotImplementedError(msg)\n\u001b[32m-> \u001b[39m\u001b[32m1396\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_input_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1397\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1398\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_shell_context_var\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_shell_parent_ident\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1399\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mget_parent\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mshell\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1400\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpassword\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   1401\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/Python/3.11/lib/python/site-packages/ipykernel/kernelbase.py:1441\u001b[39m, in \u001b[36mKernel._input_request\u001b[39m\u001b[34m(self, prompt, ident, parent, password)\u001b[39m\n\u001b[32m   1438\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m:\n\u001b[32m   1439\u001b[39m     \u001b[38;5;66;03m# re-raise KeyboardInterrupt, to truncate traceback\u001b[39;00m\n\u001b[32m   1440\u001b[39m     msg = \u001b[33m\"\u001b[39m\u001b[33mInterrupted by user\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1441\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m(msg) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1442\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[32m   1443\u001b[39m     \u001b[38;5;28mself\u001b[39m.log.warning(\u001b[33m\"\u001b[39m\u001b[33mInvalid Message:\u001b[39m\u001b[33m\"\u001b[39m, exc_info=\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: Interrupted by user"
     ]
    }
   ],
   "source": [
    "for transcript_segment_file in TRANSCRIPT_SEGMENTS_PATH.glob(\"*.csv\"):\n",
    "    \n",
    "    # check if meeting took place in specified week\n",
    "    date_str = transcript_segment_file.stem[:8]\n",
    "    try:\n",
    "        file_date = datetime.strptime(date_str, \"%Y%m%d\")\n",
    "    except ValueError:\n",
    "        # skip, meeting does not valid date\n",
    "        continue\n",
    "    if file_date < START_DATE or file_date > END_DATE:\n",
    "        # skip, meeting did not take place in specified week\n",
    "        continue\n",
    "\n",
    "\n",
    "    # manually match each transcript segment to the index of the closest aligned agenda segment from the same meeting's agenda\n",
    "    agenda_df = pd.read_csv(AGENDA_SEGMENTS_PATH / f\"{transcript_segment_file.stem}.csv\")\n",
    "    transcript_df = pd.read_csv(transcript_segment_file)\n",
    "    for idx, row in transcript_df.iterrows():\n",
    "        print(f\"transcript segment {idx}: {row['segment']}\")\n",
    "        \n",
    "        while True:\n",
    "            user_input = input(f\"enter the index of the closest aligned agenda segment (0-{len(agenda_df)-1} inclusive). enter -1 if no match: \").strip()\n",
    "            try:\n",
    "                user_input = int(user_input)\n",
    "                if user_input < -1 or user_input >= len(agenda_df):\n",
    "                    continue\n",
    "                break\n",
    "            except:\n",
    "                pass\n",
    "        \n",
    "        transcript_df.loc[idx, \"matched_agenda_segment\"] = user_input\n",
    "\n",
    "    transcript_df.to_csv(transcript_segment_file, index=False)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07e015a2",
   "metadata": {},
   "source": [
    "## Step 6: Combine agenda segments with its matched legislation and manually matched transcript segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "45a946ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33b625b5",
   "metadata": {},
   "source": [
    "The folder `_interim/transcript_segments/` should have a `.csv` file for each meeting, containing a column for the segments of the transcript. The folder `_interim/agenda_segments/` should have a `.csv` for each meeting containing the agenda segments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "22ae5422",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert TRANSCRIPT_SEGMENTS_PATH.exists()\n",
    "assert AGENDA_SEGMENTS_PATH.exists()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "137da5c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for transcript_file in TRANSCRIPT_SEGMENTS_PATH.glob(\"*.csv\"):\n",
    "\n",
    "    # check if meeting took place in specified week\n",
    "    date_str = transcript_file.stem[:8]\n",
    "    try:\n",
    "        file_date = datetime.strptime(date_str, \"%Y%m%d\")\n",
    "    except ValueError:\n",
    "        # skip, meeting does not valid date\n",
    "        continue\n",
    "    if file_date < START_DATE or file_date > END_DATE:\n",
    "        # skip, meeting did not take place in specified week\n",
    "        continue\n",
    "\n",
    "\n",
    "    agenda_file = AGENDA_SEGMENTS_PATH / f\"{transcript_file.stem}.csv\"\n",
    "    if not agenda_file.exists():\n",
    "        print(f\"!!!! AGENDA FILE NOT FOUND FOR: {transcript_file}\")\n",
    "        continue\n",
    "\n",
    "\n",
    "\n",
    "    # for each transcript segment, assign it to its matched agenda segment's row\n",
    "    agenda_df = pd.read_csv(agenda_file)\n",
    "    transcript_df = pd.read_csv(transcript_file)\n",
    "\n",
    "    agenda_df[\"matched_transcript\"] = \"NO_TRANSCRIPT\"\n",
    "\n",
    "    for idx, row in transcript_df.iterrows():\n",
    "        \n",
    "        # no match index code\n",
    "        agenda_idx = row[\"matched_agenda_segment\"]\n",
    "        if agenda_idx == -1:\n",
    "            continue\n",
    "\n",
    "        if agenda_df.loc[agenda_idx, \"matched_transcript\"] == \"NO_TRANSCRIPT\":\n",
    "            agenda_df.loc[agenda_idx, \"matched_transcript\"] = row[\"segment\"] + \"\\n\"\n",
    "        else:\n",
    "            agenda_df.loc[agenda_idx, \"matched_transcript\"] = agenda_df.loc[agenda_idx, \"matched_transcript\"] + row[\"segment\"] + \"\\n\"\n",
    "\n",
    "\n",
    "    # create combined segments by combining agenda segments, matched legislation, and matched transcript segment\n",
    "    agenda_df[\"combined_segment\"] = \"NO_SEGMENT\"\n",
    "    for agenda_idx, agenda_row in agenda_df.iterrows():\n",
    "\n",
    "        # not in transcript, so can skip\n",
    "        if agenda_row.loc[agenda_idx, \"matched_transcript\"] == \"NO_TRANSCRIPT\":\n",
    "            continue\n",
    "\n",
    "\n",
    "        combined_text = (\n",
    "            \"**Section of meeting agenda:**\\n\"\n",
    "            f\"{agenda_row.get('agenda_segment', 'NO_AGENDA')}\\n\\n\"\n",
    "            \"**Section of meeting legislation:**\\n\"\n",
    "            f\"{agenda_row.get('matched_legislation', 'NO_LEGISLATION')}\\n\\n\"\n",
    "            \"**Section of meeting transcript:**\\n\"\n",
    "            f\"{agenda_row.get('matched_transcript', 'NO_TRANSCRIPT')}\\n\\n\"\n",
    "        )\n",
    "\n",
    "        agenda_df.loc[agenda_idx, \"combined_segment\"] = combined_text\n",
    "\n",
    "\n",
    "    # save results\n",
    "    agenda_df.to_csv(agenda_file, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61177d67",
   "metadata": {},
   "source": [
    "This concludes Module 2: Transcript Processing."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
