{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b1ce511b",
   "metadata": {},
   "source": [
    "# Module 2: Transcript Processing\n",
    "- Step 1: Transcribe meeting audio\n",
    "- Step 2: Repunctuate raw transcript and split into sentences\n",
    "- Step 3: MANUAL sentence classification\n",
    "- Step 4: Segment transcription based on manual sentence classification\n",
    "- Step 5: MANUALLY match transcript segments to agenda segments of same meeting's agenda\n",
    "- Step 6: Combine agenda, legislation, and transcript segments to form combined segments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8766defb",
   "metadata": {},
   "source": [
    "Specify the week of meetings to process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7ad88ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### EDIT THIS\n",
    "MONDAY_DATE = \"YYYYMMDD\"\n",
    "FRIDAY_DATE = \"YYYYMMDD\"\n",
    "#### EDIT THIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5952f8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "WEEK = (MONDAY_DATE, FRIDAY_DATE)\n",
    "START_DATE = datetime.strptime(WEEK[0], \"%Y%m%d\")\n",
    "END_DATE = datetime.strptime(WEEK[1], \"%Y%m%d\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7f582c7",
   "metadata": {},
   "source": [
    "## Step 1: Transcribe meeting audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8e35fd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import whisper\n",
    "import regex as regex\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a928125",
   "metadata": {},
   "source": [
    "The folder `___input/audio/` should contain a `.wav` audio file for each city council meeting. Each `.wav` file should be named such that the first 8 characters are the meeting date in YYYYMMDD format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2851f8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_AUDIO_PATH = Path(\"../___input/audio/\")\n",
    "assert INPUT_AUDIO_PATH.exists()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "092aed9a",
   "metadata": {},
   "source": [
    "The agenda `.txt` files containing the transcript will be saved to `_interim/transcript/`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdcd4983",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRANSCRIPT_PATH = Path(\"../_interim/transcript/\")\n",
    "TRANSCRIPT_PATH.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e42e7504",
   "metadata": {},
   "source": [
    "Transcribe the audio with OpenAI Whisper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b59ba4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "asr_model = whisper.load_model(\"large\")\n",
    "punct_model = PunctuationModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ea2a27f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for audio_file in INPUT_AUDIO_PATH.glob(\"*.wav\"):\n",
    "        \n",
    "    # check if meeting took place in specified week\n",
    "    date_str = audio_file.stem[:8]\n",
    "    try:\n",
    "        file_date = datetime.strptime(date_str, \"%Y%m%d\")\n",
    "    except ValueError:\n",
    "        # skip, meeting does not valid date\n",
    "        continue\n",
    "    if file_date < START_DATE or file_date > END_DATE:\n",
    "        # skip, meeting did not take place in specified week\n",
    "        continue\n",
    "\n",
    "    # transcribe audio\n",
    "    stem = audio_file.stem\n",
    "    transcript_txt_path = TRANSCRIPT_PATH / f\"{stem}.txt\"\n",
    "    result = asr_model.transcribe(str(audio_file), language=\"en\")\n",
    "\n",
    "    with open(transcript_txt_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(result[\"text\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f562fa50",
   "metadata": {},
   "source": [
    "## Step 2: Repunctuate raw transcript and split into sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21d5b01a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import re\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import regex as regex\n",
    "from deepmultilingualpunctuation import PunctuationModel\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fabac6a5",
   "metadata": {},
   "source": [
    "The folder `_interim/transcript/` should now contain a `.txt` file containing the transcribed audio of each meeting. The sentences of the transcript are saved to the folder `_interim/transcript_sentences/` and the cleaned transcript text are saved back to the original destination."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b36ebbd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert TRANSCRIPT_PATH.exists()\n",
    "TRANSCRIPT_SENTENCES_PATH = Path(\"../_interim/transcript_sentences/\")\n",
    "TRANSCRIPT_SENTENCES_PATH.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb64d83e",
   "metadata": {},
   "source": [
    "Remove punctuation, clean raw text, repunctuate, and then split into sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b00f1010",
   "metadata": {},
   "outputs": [],
   "source": [
    "for raw_transcript_file in TRANSCRIPT_PATH.glob(\"*.txt\"):\n",
    "\n",
    "    # check if meeting took place in specified week\n",
    "    date_str = raw_transcript_file.stem[:8]\n",
    "    try:\n",
    "        file_date = datetime.strptime(date_str, \"%Y%m%d\")\n",
    "    except ValueError:\n",
    "        # skip, meeting does not valid date\n",
    "        continue\n",
    "    if file_date < START_DATE or file_date > END_DATE:\n",
    "        # skip, meeting did not take place in specified week\n",
    "        continue\n",
    "\n",
    "\n",
    "    # clean and remove punctuation\n",
    "    with open(raw_transcript_file, \"r\", encoding=\"utf-8\") as f:\n",
    "        raw = f.read()\n",
    "\n",
    "    raw = re.sub(r\"\\[.*?\\]\", \"\", raw)\n",
    "    # remove punctuation-based segment endings\n",
    "    raw = raw.replace(\". \", \" \").replace(\"? \", \" \").replace(\"! \", \" \").replace(\", \", \" \")\n",
    "    # remove non-Latin characters\n",
    "    raw = regex.sub(r'[^\\p{Latin}\\d\\p{P}\\s]', '', raw)\n",
    "    # normalize whitespace and remove filler words\n",
    "    raw = re.sub(r'\\b(?:uh|um)+\\b[,.]?\\s*', '', raw, flags=re.IGNORECASE)\n",
    "    raw = re.sub(r'\\s+', ' ', raw)\n",
    "    clean =  raw.strip()\n",
    "\n",
    "    # repunctuate text\n",
    "    punctuated_text = punct_model.restore_punctuation(clean)\n",
    "\n",
    "    # split into sentences\n",
    "    sentences = re.findall(r'[^.!?]*[.!?]', punctuated_text)\n",
    "    sentences = [s.strip() for s in sentences if s.strip()]\n",
    "\n",
    "\n",
    "    # save sentences to .csv file\n",
    "    stem = raw_transcript_file.stem\n",
    "    csv_output_path = TRANSCRIPT_SENTENCES_PATH / f\"{stem}.csv\"\n",
    "    with open(csv_output_path, \"w\", newline='', encoding=\"utf-8\") as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow([\"sentence\", \"classification\"])\n",
    "        for sentence in sentences:\n",
    "            writer.writerow([sentence, \"x\"])\n",
    "\n",
    "    # convert sentences to cleaned transcript and save cleaned transcript\n",
    "    clean_transcript_file_path = TRANSCRIPT_PATH / f\"{stem}.txt\"\n",
    "    df = pd.read_csv(csv_output_path)\n",
    "    full_text = \" \".join(df[\"sentence\"].dropna().astype(str))\n",
    "    with open(clean_transcript_file_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(full_text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af393ab5",
   "metadata": {},
   "source": [
    "## Step 3: MANUAL transcript segmentation via sentence classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4abae943",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7da1e1a",
   "metadata": {},
   "source": [
    "Now, the transcript sentences should be saved to the folder `_interim/transcript_sentences/`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "171706dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert TRANSCRIPT_SENTENCES_PATH.exists()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b4ba922",
   "metadata": {},
   "outputs": [],
   "source": [
    "for transcript_sentences_file in TRANSCRIPT_SENTENCES_PATH.glob(\"*.csv\"):\n",
    "    \n",
    "    # check if meeting took place in specified week\n",
    "    date_str = transcript_sentences_file.stem[:8]\n",
    "    try:\n",
    "        file_date = datetime.strptime(date_str, \"%Y%m%d\")\n",
    "    except ValueError:\n",
    "        # skip, meeting does not valid date\n",
    "        continue\n",
    "    if file_date < START_DATE or file_date > END_DATE:\n",
    "        # skip, meeting did not take place in specified week\n",
    "        continue\n",
    "\n",
    "    df = pd.read_csv(transcript_sentences_file)\n",
    "\n",
    "\n",
    "    # manual classification instructions\n",
    "    print(\"Label each sentence as:\")\n",
    "    print(\"  b - beginning of new topic\")\n",
    "    print(\"  p - beginning of new public comment topic\")\n",
    "    print(\"  i - inside a topic\")\n",
    "    print(\"Type 'back' to go to the previous sentence.\")\n",
    "    print(\"Type 'quit' to stop early and save your progress.\\n\")\n",
    "\n",
    "    # manual classification loop\n",
    "    idx = 0\n",
    "    while idx < len(df):\n",
    "        sentence = df.loc[idx, \"sentence\"]\n",
    "        current_label = df.loc[idx, \"classification\"]\n",
    "\n",
    "        print(f\"\\n{idx + 1}/{len(df)}: {sentence}\")\n",
    "        if current_label:\n",
    "            print(f\"current label: {current_label}\")\n",
    "\n",
    "        user_input = input(\"Label (b/p/i, or 'back', 'quit'): \").strip().lower()\n",
    "\n",
    "        if user_input in {\"b\", \"p\", \"i\"}:\n",
    "            df.at[idx, \"classification\"] = user_input\n",
    "            idx += 1\n",
    "        elif user_input == \"back\":\n",
    "            if idx > 0:\n",
    "                idx -= 1\n",
    "            else:\n",
    "                print(\"!!!! ALREADY AT BEGINNING\")\n",
    "        elif user_input == \"quit\":\n",
    "            break\n",
    "        else:\n",
    "            print(\"!!!! INVALID, PLEASE ENTER 'b', 'p', 'i', 'back', or 'quit'\")\n",
    "\n",
    "    # save classifications\n",
    "    df.to_csv(transcript_sentences_file, index=False)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33c42f92",
   "metadata": {},
   "source": [
    "## Step 4: Segment transcript using manual classification of sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c9365f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import csv\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f38aaf25",
   "metadata": {},
   "source": [
    "The folder `_interim/transcript_sentences/` should have a `.csv` file for each meeting, containing a column for the sentences and another column for the manual classification. The segments will be saved to the folder `_interim/transcript_segments/`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd18adcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert TRANSCRIPT_SENTENCES_PATH.exists()\n",
    "TRANSCRIPT_SEGMENTS_PATH = Path(\"../_interim/transcript_segments/\")\n",
    "TRANSCRIPT_SEGMENTS_PATH.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd137a2f",
   "metadata": {},
   "source": [
    "Combine adjacent sentences in the transcript into segments. The `b` and `p` labels denote beginning of new segments. The `i` label denotes a continuation of a segment. Do not include segments that start with `p` sentences in the final segment file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98294843",
   "metadata": {},
   "outputs": [],
   "source": [
    "for transcript_sentences_file in TRANSCRIPT_SENTENCES_PATH.glob(\"*.csv\"):\n",
    "\n",
    "    # check if meeting took place in specified week\n",
    "    date_str = transcript_sentences_file.stem[:8]\n",
    "    try:\n",
    "        file_date = datetime.strptime(date_str, \"%Y%m%d\")\n",
    "    except ValueError:\n",
    "        # skip, meeting does not valid date\n",
    "        continue\n",
    "    if file_date < START_DATE or file_date > END_DATE:\n",
    "        # skip, meeting did not take place in specified week\n",
    "        continue\n",
    "\n",
    "\n",
    "    # combine adjacent sentences into segments based on each sentence's classification\n",
    "    df = pd.read_csv(transcript_sentences_file)\n",
    "    # remove irrelevant rows\n",
    "    df = df[df[\"classification\"] != \"f\"].reset_index(drop=True)\n",
    "    # skip any initial content before the first 'b' or 'p'\n",
    "    start_index = df[df[\"classification\"].isin([\"b\", \"p\"])].index.min()\n",
    "    df = df.iloc[start_index:].reset_index(drop=True)\n",
    "\n",
    "    # do not include public comment segments\n",
    "    segments = []\n",
    "    current_segment = \"\"\n",
    "    is_public_comment = False\n",
    "    in_segment = False\n",
    "    for _, row in df.iterrows():\n",
    "        label = row[\"classification\"]\n",
    "        sentence = row[\"sentence\"]\n",
    "\n",
    "        if label == \"i\":\n",
    "            current_segment += sentence + \" \"\n",
    "        else:\n",
    "            # iff we're finishing a segment, and it's not a public comment, store it\n",
    "            if in_segment and not is_public_comment:\n",
    "                segments.append(current_segment.strip())\n",
    "\n",
    "            current_segment = sentence + \" \"\n",
    "            in_segment = True\n",
    "            is_public_comment = (label == \"p\")\n",
    "\n",
    "    # handle final segment\n",
    "    if in_segment and not is_public_comment:\n",
    "        segments.append(current_segment.strip())\n",
    "\n",
    "    # save segments to .csv\n",
    "    segments_file_path = TRANSCRIPT_SEGMENTS_PATH / f\"{transcript_sentences_file.stem}.csv\"\n",
    "    with open(segments_file_path, mode=\"w\", newline='', encoding=\"utf-8\") as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow([\"segment\", \"matched_agenda_segment\"])\n",
    "        for segment in segments:\n",
    "            writer.writerow([segment, -1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95f67448",
   "metadata": {},
   "source": [
    "## Step 5: MANUALLY match transcript segment to corresponding agenda segment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1213c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20e26793",
   "metadata": {},
   "source": [
    "The folder `_interim/transcript_segments/` should have a `.csv` file for each meeting, containing a column for the segments of the transcript. The folder `_interim/agenda_segments/` should have a `.csv` for each meeting containing the agenda segments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "888be5c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert TRANSCRIPT_SEGMENTS_PATH.exists()\n",
    "AGENDA_SEGMENTS_PATH = Path(\"../_interim/agenda_segments/\")\n",
    "assert AGENDA_SEGMENTS_PATH.exists()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a630a7b1",
   "metadata": {},
   "source": [
    "Manually match each transcript segment to the closest aligned agenda segment from the same meeting's agenda."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec75e159",
   "metadata": {},
   "outputs": [],
   "source": [
    "for transcript_segment_file in TRANSCRIPT_SEGMENTS_PATH.glob(\"*.csv\"):\n",
    "    \n",
    "    # check if meeting took place in specified week\n",
    "    date_str = transcript_segment_file.stem[:8]\n",
    "    try:\n",
    "        file_date = datetime.strptime(date_str, \"%Y%m%d\")\n",
    "    except ValueError:\n",
    "        # skip, meeting does not valid date\n",
    "        continue\n",
    "    if file_date < START_DATE or file_date > END_DATE:\n",
    "        # skip, meeting did not take place in specified week\n",
    "        continue\n",
    "\n",
    "\n",
    "    # manually match each transcript segment to the index of the closest aligned agenda segment from the same meeting's agenda\n",
    "    agenda_df = pd.read_csv(AGENDA_SEGMENTS_PATH / f\"{transcript_segment_file.stem}.csv\")\n",
    "    transcript_df = pd.read_csv(transcript_segment_file)\n",
    "    for idx, row in transcript_df.iterrows():\n",
    "        print(f\"transcript segment {idx}: {row['segment']}\")\n",
    "        \n",
    "        while True:\n",
    "            user_input = input(f\"enter the index of the closest aligned agenda segment (0-{len(agenda_df)-1} inclusive). enter -1 if no match: \").strip()\n",
    "            try:\n",
    "                user_input = int(user_input)\n",
    "                if user_input < -1 or user_input >= len(agenda_df):\n",
    "                    continue\n",
    "                break\n",
    "            except:\n",
    "                pass\n",
    "        \n",
    "        transcript_df.loc[idx, \"matched_agenda_segment\"] = user_input\n",
    "\n",
    "    transcript_df.to_csv(transcript_segment_file, index=False)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07e015a2",
   "metadata": {},
   "source": [
    "## Step 6: Combine agenda segments with its matched legislation and manually matched transcript segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45a946ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33b625b5",
   "metadata": {},
   "source": [
    "The folder `_interim/transcript_segments/` should have a `.csv` file for each meeting, containing a column for the segments of the transcript. The folder `_interim/agenda_segments/` should have a `.csv` for each meeting containing the agenda segments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22ae5422",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert TRANSCRIPT_SEGMENTS_PATH.exists()\n",
    "assert AGENDA_SEGMENTS_PATH.exists()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "137da5c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for transcript_file in TRANSCRIPT_SEGMENTS_PATH.glob(\"*.csv\"):\n",
    "\n",
    "    # check if meeting took place in specified week\n",
    "    date_str = transcript_file.stem[:8]\n",
    "    try:\n",
    "        file_date = datetime.strptime(date_str, \"%Y%m%d\")\n",
    "    except ValueError:\n",
    "        # skip, meeting does not valid date\n",
    "        continue\n",
    "    if file_date < START_DATE or file_date > END_DATE:\n",
    "        # skip, meeting did not take place in specified week\n",
    "        continue\n",
    "\n",
    "\n",
    "    agenda_file = AGENDA_SEGMENTS_PATH / f\"{transcript_file.stem}.csv\"\n",
    "    if not agenda_file.exists():\n",
    "        print(f\"!!!! AGENDA FILE NOT FOUND FOR: {transcript_file}\")\n",
    "        continue\n",
    "\n",
    "\n",
    "\n",
    "    # for each transcript segment, assign it to its matched agenda segment's row\n",
    "    agenda_df = pd.read_csv(agenda_file)\n",
    "    transcript_df = pd.read_csv(transcript_file)\n",
    "\n",
    "    agenda_df[\"matched_transcript\"] = \"NO_TRANSCRIPT\"\n",
    "\n",
    "    for idx, row in transcript_df.iterrows():\n",
    "        \n",
    "        # no match index code\n",
    "        agenda_idx = row[\"matched_agenda_segment\"]\n",
    "        if agenda_idx == -1:\n",
    "            continue\n",
    "\n",
    "        if agenda_df.loc[agenda_idx, \"matched_transcript\"] == \"NO_TRANSCRIPT\":\n",
    "            agenda_df.loc[agenda_idx, \"matched_transcript\"] = row[\"segment\"] + \"\\n\"\n",
    "        else:\n",
    "            agenda_df.loc[agenda_idx, \"matched_transcript\"] = agenda_df.loc[agenda_idx, \"matched_transcript\"] + row[\"segment\"] + \"\\n\"\n",
    "\n",
    "\n",
    "    # create combined segments by combining agenda segments, matched legislation, and matched transcript segment\n",
    "    agenda_df[\"combined_segment\"] = \"NO_SEGMENT\"\n",
    "    for agenda_idx, agenda_row in agenda_df.iterrows():\n",
    "\n",
    "        # not in transcript, so can skip\n",
    "        if agenda_row.loc[agenda_idx, \"matched_transcript\"] == \"NO_TRANSCRIPT\":\n",
    "            continue\n",
    "\n",
    "\n",
    "        combined_text = (\n",
    "            \"**Section of meeting agenda:**\\n\"\n",
    "            f\"{agenda_row.get('agenda_segment', 'NO_AGENDA')}\\n\\n\"\n",
    "            \"**Section of meeting legislation:**\\n\"\n",
    "            f\"{agenda_row.get('matched_legislation', 'NO_LEGISLATION')}\\n\\n\"\n",
    "            \"**Section of meeting transcript:**\\n\"\n",
    "            f\"{agenda_row.get('matched_transcript', 'NO_TRANSCRIPT')}\\n\\n\"\n",
    "        )\n",
    "\n",
    "        agenda_df.loc[agenda_idx, \"combined_segment\"] = combined_text\n",
    "\n",
    "\n",
    "    # save results\n",
    "    agenda_df.to_csv(agenda_file, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61177d67",
   "metadata": {},
   "source": [
    "This concludes Module 2: Transcript Processing."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
